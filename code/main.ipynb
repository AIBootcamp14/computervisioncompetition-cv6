{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f534d9",
   "metadata": {},
   "source": [
    "### import & seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50b6594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import & seed ê³ ì •\n",
    "import os, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True  # ì†ë„ ìš°ì„ \n",
    "# torch.use_deterministic_algorithms(False)  # ì¬í˜„ì„± ìš°ì„ ì´ë©´ Trueë¡œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee03c60",
   "metadata": {},
   "source": [
    "### Settings (path/hyper parameters/device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "818114c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings(path/hyper parameters/device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_path = '../data'\n",
    "model_name = 'tf_efficientnet_b6.aa_in1k'  # safe_create_modelì´ ì•Œì•„ì„œ í´ë°± ì²˜ë¦¬\n",
    "\n",
    "NUM_CLASSES = 17\n",
    "img_size = 528        # 224, 456, 528 ë“±\n",
    "LR = 1e-3\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "num_workers = 32      # í™˜ê²½ì— ë”°ë¼ 8~16 ê¶Œì¥\n",
    "N_REPEAT = 5          # ê°™ì€ ì›ë³¸ì„ í•œ ì—í­ì— 3ë²ˆ ë…¸ì¶œ(ì„œë¡œ ë‹¤ë¥¸ ì¦ê°• ì¡°í•©)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc8635",
   "metadata": {},
   "source": [
    "### dataset & repeat augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ab6806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset & repeat augmentation\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"CSV: (filename, target) í˜•ì‹ ê°€ì •. í…ŒìŠ¤íŠ¸ì—ì„œëŠ” target ì¹¼ëŸ¼ì´ dummyì—¬ë„ OK.\"\"\"\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path).values  # [[name, target], ...]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.img_dir, name)))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "class RepeatAugDataset(Dataset):\n",
    "    \"\"\"ê°™ì€ ìƒ˜í”Œì„ repeatsë²ˆ ë…¸ì¶œ(í˜¸ì¶œë§ˆë‹¤ transformì´ ë‹¬ë¼ì§€ë¯€ë¡œ ì„œë¡œ ë‹¤ë¥¸ ì¦ê°• ì¡°í•©ìœ¼ë¡œ í•™ìŠµ).\"\"\"\n",
    "    def __init__(self, base_dataset, repeats: int = 3):\n",
    "        self.base = base_dataset\n",
    "        self.repeats = repeats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base) * self.repeats\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_idx = idx // self.repeats\n",
    "        return self.base[base_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a948649",
   "metadata": {},
   "source": [
    "### transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02c329af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_678086/832637540.py:5: UserWarning: Argument(s) 'pad_mode, pad_val' are not valid for transform Perspective\n",
      "  A.Perspective(scale=(0.05, 0.12), keep_size=True,\n",
      "/tmp/ipykernel_678086/832637540.py:7: UserWarning: Argument(s) 'cval, mode' are not valid for transform Affine\n",
      "  A.Affine(translate_percent=(0.0, 0.08), scale=(0.95, 1.05),\n",
      "/tmp/ipykernel_678086/832637540.py:9: UserWarning: Argument(s) 'min_holes, max_holes, min_height, max_height, min_width, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(min_holes=1, max_holes=4,\n",
      "/tmp/ipykernel_678086/832637540.py:13: UserWarning: Argument(s) 'min_holes, max_holes, min_height, max_height, min_width, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(min_holes=1, max_holes=4,\n",
      "/tmp/ipykernel_678086/832637540.py:23: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n",
      "  A.Rotate(limit=180, border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),\n",
      "/tmp/ipykernel_678086/832637540.py:29: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(int(img_size*1.15), int(img_size*1.15),\n",
      "/tmp/ipykernel_678086/832637540.py:34: UserWarning: Argument(s) 'scale_min, scale_max' are not valid for transform Downscale\n",
      "  A.Downscale(scale_min=0.85, scale_max=0.96, p=1.0),\n",
      "/tmp/ipykernel_678086/832637540.py:36: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=40, quality_upper=85, p=1.0),\n",
      "/tmp/ipykernel_678086/832637540.py:37: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 20.0), p=1.0),\n",
      "/tmp/ipykernel_678086/832637540.py:61: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(img_size, img_size, border_mode=cv2.BORDER_CONSTANT, value=255),\n"
     ]
    }
   ],
   "source": [
    "# ===== Toggle here =====\n",
    "N_SOME = 4  # â† A/B í…ŒìŠ¤íŠ¸ ì‹œ 3 ë˜ëŠ” 4ë¡œë§Œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "heavy_one = A.OneOf([  # í—¤ë¹„ê¸‰: ìµœëŒ€ 1ê°œë§Œ ì„ íƒ\n",
    "    A.Perspective(scale=(0.05, 0.12), keep_size=True,\n",
    "                  pad_mode=cv2.BORDER_CONSTANT, pad_val=255),\n",
    "    A.Affine(translate_percent=(0.0, 0.08), scale=(0.95, 1.05),\n",
    "             shear=(-12, 12), cval=255, mode=cv2.BORDER_CONSTANT),\n",
    "    A.CoarseDropout(min_holes=1, max_holes=4,\n",
    "                    min_height=int(img_size*0.08), max_height=int(img_size*0.30),\n",
    "                    min_width=int(img_size*0.15),  max_width=int(img_size*0.40),\n",
    "                    fill_value=0),\n",
    "    A.CoarseDropout(min_holes=1, max_holes=4,\n",
    "                    min_height=int(img_size*0.08), max_height=int(img_size*0.30),\n",
    "                    min_width=int(img_size*0.15),  max_width=int(img_size*0.40),\n",
    "                    fill_value=255),\n",
    "    A.MotionBlur(blur_limit=(7, 11), allow_shifted=True),\n",
    "], p=1.0)\n",
    "\n",
    "light_pool = [\n",
    "    # ê¸°ì¡´ ë³€í˜•ë“¤(ì„ íƒë˜ë©´ í•­ìƒ ì ìš©ë˜ë„ë¡ p=1.0; ì ìš© ê°œìˆ˜ëŠ” SomeOfì˜ nìœ¼ë¡œ ì œì–´)\n",
    "    A.RandomRotate90(p=1.0),\n",
    "    A.Rotate(limit=180, border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    A.RandomBrightnessContrast(0.12, 0.12, p=1.0),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=int(img_size*1.15), interpolation=cv2.INTER_CUBIC),\n",
    "        A.PadIfNeeded(int(img_size*1.15), int(img_size*1.15),\n",
    "                      border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),\n",
    "        A.RandomResizedCrop(size=(img_size, img_size),\n",
    "                            scale=(0.85, 1.0), ratio=(0.9, 1.1), p=1.0),\n",
    "    ]),\n",
    "    A.Downscale(scale_min=0.85, scale_max=0.96, p=1.0),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "    A.ImageCompression(quality_lower=40, quality_upper=85, p=1.0),\n",
    "    A.GaussNoise(var_limit=(5.0, 20.0), p=1.0),\n",
    "\n",
    "    # ì»¬ëŸ¬/í†¤/ì±„ë„ ë³€í˜•(ì‹¤ë¬¼ ë°ì´í„°ì˜ ìƒ‰ ìºìŠ¤íŠ¸ ëŒ€ì‘)\n",
    "    A.HueSaturationValue(hue_shift_limit=12, sat_shift_limit=25, val_shift_limit=15, p=1.0),\n",
    "    A.RandomGamma(gamma_limit=(60, 140), p=1.0),\n",
    "    A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=1.0),\n",
    "    A.CLAHE(clip_limit=(1, 3), tile_grid_size=(8, 8), p=1.0),\n",
    "    A.ToGray(p=1.0),\n",
    "    A.InvertImg(p=1.0),\n",
    "]\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.SomeOf(\n",
    "        [heavy_one] + light_pool,  # í—¤ë¹„ 1ê°œê¹Œì§€ + ë¼ì´íŠ¸ í’€ì—ì„œ ì„ íƒ\n",
    "        n=N_SOME,\n",
    "        p=1.0\n",
    "    ),\n",
    "    A.Resize(img_size, img_size, interpolation=cv2.INTER_CUBIC),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_CUBIC),\n",
    "    A.PadIfNeeded(img_size, img_size, border_mode=cv2.BORDER_CONSTANT, value=255),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd373b0",
   "metadata": {},
   "source": [
    "### data load & train/val split -> dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78f31043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1570, 197)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [ì…€ 5-K] K-Fold ë¶„í•  & DataLoader ì¤€ë¹„ (ë¬´TTA)\n",
    "FOLDS = 5\n",
    "\n",
    "# ì „ì²´ train ë¡œë“œ (ë³€ê²½ ì—†ìŒ)\n",
    "train_dataset_full = ImageDataset(\n",
    "    os.path.join(data_path, \"train.csv\"),\n",
    "    os.path.join(data_path, \"train\"),\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¡œë”ëŠ” í´ë“œì™€ ë¬´ê´€í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ ë§Œë“¤ì–´ ë‘¡ë‹ˆë‹¤.\n",
    "test_dataset = ImageDataset(\n",
    "    os.path.join(data_path, \"sample_submission.csv\"),\n",
    "    os.path.join(data_path, \"test\"),\n",
    "    transform=test_transforms\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# í´ë“œ ë¶„í• ì—ì„œ ì‚¬ìš©ë  ë¼ë²¨\n",
    "y_all = train_dataset_full.df[:, 1].astype(int)\n",
    "\n",
    "# StratifiedKFold ê°ì²´ (ì…”í”Œ ê¶Œì¥)\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# ì´í›„ ì…€ 8ì—ì„œ í´ë“œ ë£¨í”„ë¥¼ ëŒë¦´ ê²ƒì´ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¡œë”ë¥¼ ë§Œë“¤ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "# ê° foldë§ˆë‹¤ train/val Subsetê³¼ DataLoaderëŠ” ì…€ 8ì—ì„œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "len(train_dataset_full), len(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ec9c4",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c9abe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def safe_create_model(model_name: str, num_classes: int, device):\n",
    "    tried = []\n",
    "    def _try(name, **kw):\n",
    "        tried.append(name)\n",
    "        return timm.create_model(name, pretrained=True, num_classes=num_classes, **kw).to(device)\n",
    "\n",
    "    try:\n",
    "        return _try(model_name, drop_rate=0.3, drop_path_rate=0.1)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return _try(model_name, drop_rate=0.3)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "\n",
    "    fallbacks = [\n",
    "        model_name.replace('.', '_'),\n",
    "        'tf_efficientnet_b6_ns',\n",
    "        'tf_efficientnet_b6',\n",
    "        'tf_efficientnet_b4_ns',\n",
    "        'convnext_tiny',\n",
    "    ]\n",
    "    for fb in fallbacks:\n",
    "        try:\n",
    "            return _try(fb, drop_rate=0.3)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    raise RuntimeError(f\"create_model ì‹¤íŒ¨. ì‹œë„: {tried} | last_err: {last_err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35373d",
   "metadata": {},
   "source": [
    "### train/valid roof definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "960b3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/valid roof definition\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scheduler=None):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=(device.type == \"cuda\")):\n",
    "            logits = model(images)\n",
    "            loss = loss_fn(logits, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # âœ… ë°°ì¹˜ ë‹¨ìœ„ë¡œ LR ìŠ¤ì¼€ì¤„ ì§„í–‰\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # --- ë©”íŠ¸ë¦­ ëˆ„ì  ---\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(logits.argmax(1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        # ì§„í–‰ë°”ì— í˜„ì¬ LR í‘œì‹œ(ì„ íƒ)\n",
    "        if scheduler is not None:\n",
    "            # optimizerì— ê·¸ë£¹ì´ ì—¬ëŸ¬ ê°œë©´ ì²« ê·¸ë£¹ ê¸°ì¤€\n",
    "            curr_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            pbar.set_description(f\"Loss: {loss.item():.4f} | LR: {curr_lr:.2e}\")\n",
    "        else:\n",
    "            pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # í‰ê· (ë°°ì¹˜ í‰ê· ). ìƒ˜í”Œ ê°€ì¤‘ í‰ê· ì„ ì›í•˜ë©´ batch_sizeë¡œ ê°€ì¤‘í•˜ì„¸ìš”.\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1  = f1_score(targets_list, preds_list, average=\"macro\")\n",
    "\n",
    "    return {\"train_loss\": train_loss, \"train_acc\": train_acc, \"train_f1\": train_f1}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    for images, targets in tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with autocast():\n",
    "            logits = model(images)\n",
    "            loss = loss_fn(logits, targets)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        preds_list.extend(logits.argmax(1).cpu().numpy())\n",
    "        targets_list.extend(targets.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1  = f1_score(targets_list, preds_list, average='macro')\n",
    "    return {\"val_loss\": val_loss, \"val_acc\": val_acc, \"val_f1\": val_f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e597d",
   "metadata": {},
   "source": [
    "### model/loss/optim/scheduler & train loof + checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a6040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 0 / 4 ==========\n",
      "\n",
      "[Fold 0] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2723 | LR: 9.76e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.7511 | Val F1: 0.8462 | Train Loss: 0.7240 | Val Loss: 0.3694 | Elapsed: 130.09s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5600 | LR: 9.05e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8693 | Val F1: 0.8741 | Train Loss: 0.3377 | Val Loss: 0.3308 | Elapsed: 130.08s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0494 | LR: 7.94e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:05<00:00,  3.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9129 | Val F1: 0.9028 | Train Loss: 0.2224 | Val Loss: 0.2415 | Elapsed: 130.78s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1389 | LR: 6.55e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9344 | Val F1: 0.9164 | Train Loss: 0.1680 | Val Loss: 0.2906 | Elapsed: 130.41s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0806 | LR: 5.00e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9475 | Val F1: 0.9204 | Train Loss: 0.1278 | Val Loss: 0.2195 | Elapsed: 130.45s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0432 | LR: 3.46e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9668 | Val F1: 0.9231 | Train Loss: 0.0799 | Val Loss: 0.2287 | Elapsed: 129.97s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1890 | LR: 2.07e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9818 | Val F1: 0.9196 | Train Loss: 0.0520 | Val Loss: 0.2259 | Elapsed: 130.26s\n",
      "\n",
      "[Fold 0] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0011 | LR: 9.64e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9867 | Val F1: 0.9455 | Train Loss: 0.0352 | Val Loss: 0.1647 | Elapsed: 130.29s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006 | LR: 2.54e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9909 | Val F1: 0.9358 | Train Loss: 0.0240 | Val Loss: 0.1836 | Elapsed: 129.95s\n",
      "\n",
      "[Fold 0] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002 | LR: 1.00e-06: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9929 | Val F1: 0.9393 | Train Loss: 0.0228 | Val Loss: 0.1764 | Elapsed: 130.20s\n",
      "\n",
      "========== Fold 1 / 4 ==========\n",
      "\n",
      "[Fold 1] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6145 | LR: 9.76e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.7458 | Val F1: 0.8567 | Train Loss: 0.7428 | Val Loss: 0.3987 | Elapsed: 129.77s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1188 | LR: 9.05e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8701 | Val F1: 0.8952 | Train Loss: 0.3316 | Val Loss: 0.2927 | Elapsed: 130.38s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1994 | LR: 7.94e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:05<00:00,  3.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9086 | Val F1: 0.8839 | Train Loss: 0.2474 | Val Loss: 0.2932 | Elapsed: 130.58s\n",
      "\n",
      "[Fold 1] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2722 | LR: 6.55e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9341 | Val F1: 0.9024 | Train Loss: 0.1787 | Val Loss: 0.2738 | Elapsed: 130.60s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2397 | LR: 5.00e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9491 | Val F1: 0.8941 | Train Loss: 0.1312 | Val Loss: 0.2863 | Elapsed: 129.69s\n",
      "\n",
      "[Fold 1] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0535 | LR: 3.46e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9629 | Val F1: 0.9211 | Train Loss: 0.0983 | Val Loss: 0.2574 | Elapsed: 130.40s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0585 | LR: 2.07e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9783 | Val F1: 0.9179 | Train Loss: 0.0583 | Val Loss: 0.2915 | Elapsed: 130.17s\n",
      "\n",
      "[Fold 1] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0183 | LR: 9.64e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9867 | Val F1: 0.9255 | Train Loss: 0.0359 | Val Loss: 0.3343 | Elapsed: 129.80s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0650 | LR: 2.54e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9923 | Val F1: 0.9319 | Train Loss: 0.0239 | Val Loss: 0.3328 | Elapsed: 130.18s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0240 | LR: 1.00e-06: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9924 | Val F1: 0.9343 | Train Loss: 0.0229 | Val Loss: 0.3394 | Elapsed: 130.55s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "========== Fold 2 / 4 ==========\n",
      "\n",
      "[Fold 2] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5677 | LR: 9.76e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:05<00:00,  3.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.7533 | Val F1: 0.8543 | Train Loss: 0.7228 | Val Loss: 0.3461 | Elapsed: 130.58s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0921 | LR: 9.05e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8833 | Val F1: 0.9214 | Train Loss: 0.3164 | Val Loss: 0.2050 | Elapsed: 129.90s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0399 | LR: 7.94e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9099 | Val F1: 0.9210 | Train Loss: 0.2402 | Val Loss: 0.2281 | Elapsed: 129.63s\n",
      "\n",
      "[Fold 2] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6780 | LR: 6.55e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9303 | Val F1: 0.9353 | Train Loss: 0.1933 | Val Loss: 0.1588 | Elapsed: 130.37s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0057 | LR: 5.00e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9594 | Val F1: 0.9285 | Train Loss: 0.1075 | Val Loss: 0.2000 | Elapsed: 130.33s\n",
      "\n",
      "[Fold 2] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0423 | LR: 3.46e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9709 | Val F1: 0.9334 | Train Loss: 0.0845 | Val Loss: 0.1766 | Elapsed: 130.19s\n",
      "\n",
      "[Fold 2] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002 | LR: 2.07e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9804 | Val F1: 0.9431 | Train Loss: 0.0543 | Val Loss: 0.1769 | Elapsed: 130.30s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000 | LR: 9.64e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:03<00:00,  3.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9841 | Val F1: 0.9416 | Train Loss: 0.0443 | Val Loss: 0.1729 | Elapsed: 130.19s\n",
      "\n",
      "[Fold 2] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004 | LR: 2.54e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:05<00:00,  3.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9891 | Val F1: 0.9411 | Train Loss: 0.0318 | Val Loss: 0.1617 | Elapsed: 130.68s\n",
      "\n",
      "[Fold 2] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001 | LR: 1.00e-06: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9910 | Val F1: 0.9369 | Train Loss: 0.0225 | Val Loss: 0.1693 | Elapsed: 129.80s\n",
      "\n",
      "========== Fold 3 / 4 ==========\n",
      "\n",
      "[Fold 3] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5218 | LR: 9.76e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.7652 | Val F1: 0.8479 | Train Loss: 0.6954 | Val Loss: 0.3672 | Elapsed: 130.41s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2006 | LR: 9.05e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8902 | Val F1: 0.8754 | Train Loss: 0.2973 | Val Loss: 0.3138 | Elapsed: 130.37s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3715 | LR: 7.94e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9136 | Val F1: 0.8995 | Train Loss: 0.2237 | Val Loss: 0.2313 | Elapsed: 130.00s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0568 | LR: 6.55e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9374 | Val F1: 0.9377 | Train Loss: 0.1681 | Val Loss: 0.2245 | Elapsed: 129.54s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0975 | LR: 5.00e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9554 | Val F1: 0.9161 | Train Loss: 0.1177 | Val Loss: 0.2584 | Elapsed: 130.23s\n",
      "\n",
      "[Fold 3] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0249 | LR: 3.46e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9682 | Val F1: 0.9206 | Train Loss: 0.0826 | Val Loss: 0.2322 | Elapsed: 130.11s\n",
      "\n",
      "[Fold 3] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004 | LR: 2.07e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9739 | Val F1: 0.9257 | Train Loss: 0.0669 | Val Loss: 0.2338 | Elapsed: 130.81s\n",
      "\n",
      "[Fold 3] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0116 | LR: 9.64e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:05<00:00,  3.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9856 | Val F1: 0.9388 | Train Loss: 0.0391 | Val Loss: 0.2489 | Elapsed: 130.60s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016 | LR: 2.54e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9874 | Val F1: 0.9415 | Train Loss: 0.0294 | Val Loss: 0.2380 | Elapsed: 130.32s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002 | LR: 1.00e-06: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9883 | Val F1: 0.9277 | Train Loss: 0.0280 | Val Loss: 0.2364 | Elapsed: 130.18s\n",
      "\n",
      "========== Fold 4 / 4 ==========\n",
      "\n",
      "[Fold 4] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0954 | LR: 9.76e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.7669 | Val F1: 0.8466 | Train Loss: 0.6790 | Val Loss: 0.4332 | Elapsed: 130.55s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2095 | LR: 9.05e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:05<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8793 | Val F1: 0.8695 | Train Loss: 0.3154 | Val Loss: 0.3105 | Elapsed: 130.41s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3639 | LR: 7.94e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9037 | Val F1: 0.9207 | Train Loss: 0.2398 | Val Loss: 0.1944 | Elapsed: 129.92s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0856 | LR: 6.55e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9414 | Val F1: 0.9212 | Train Loss: 0.1586 | Val Loss: 0.2259 | Elapsed: 129.96s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0602 | LR: 5.00e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9495 | Val F1: 0.9163 | Train Loss: 0.1246 | Val Loss: 0.2487 | Elapsed: 130.26s\n",
      "\n",
      "[Fold 4] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0156 | LR: 3.46e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:05<00:00,  3.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9715 | Val F1: 0.9293 | Train Loss: 0.0764 | Val Loss: 0.2365 | Elapsed: 130.79s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0023 | LR: 2.07e-04: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9798 | Val F1: 0.9253 | Train Loss: 0.0519 | Val Loss: 0.2473 | Elapsed: 130.39s\n",
      "\n",
      "[Fold 4] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0030 | LR: 9.64e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9880 | Val F1: 0.9338 | Train Loss: 0.0352 | Val Loss: 0.2451 | Elapsed: 130.41s\n",
      "âœ… Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0714 | LR: 2.54e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:04<00:00,  3.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9920 | Val F1: 0.9250 | Train Loss: 0.0218 | Val Loss: 0.2629 | Elapsed: 130.16s\n",
      "\n",
      "[Fold 4] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000 | LR: 1.00e-06: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [02:05<00:00,  3.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9906 | Val F1: 0.9230 | Train Loss: 0.0224 | Val Loss: 0.2895 | Elapsed: 130.51s\n",
      "\n",
      "Fold best checkpoints: ['../results/checkpoints/tf_efficientnet_b6.aa_in1k_v3_fold0.pth', '../results/checkpoints/tf_efficientnet_b6.aa_in1k_v3_fold1.pth', '../results/checkpoints/tf_efficientnet_b6.aa_in1k_v3_fold2.pth', '../results/checkpoints/tf_efficientnet_b6.aa_in1k_v3_fold3.pth', '../results/checkpoints/tf_efficientnet_b6.aa_in1k_v3_fold4.pth']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model/loss/optim/scheduler & train loof + checkpoint\n",
    "model = safe_create_model(model_name, NUM_CLASSES, device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "version = 'v3'\n",
    "best_val_f1 = 0.0\n",
    "patience, bad = 4, 0\n",
    "\n",
    "best_ckpts = []  # í´ë“œë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê²½ë¡œ ì €ì¥\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(np.arange(len(train_dataset_full)), y_all)):\n",
    "    print(f\"\\n========== Fold {fold} / {FOLDS-1} ==========\")\n",
    "\n",
    "    # --- í´ë“œë³„ Subset\n",
    "    tr_subset = Subset(train_dataset_full, tr_idx)\n",
    "    va_subset = Subset(train_dataset_full, va_idx)\n",
    "\n",
    "    # --- í•™ìŠµë§Œ ë°˜ë³µ ë…¸ì¶œ (ê°™ì€ ì›ë³¸ì„ ì„œë¡œ ë‹¤ë¥¸ ì¦ê°• ì¡°í•©ìœ¼ë¡œ NíšŒ ë³´ì´ê¸°)\n",
    "    tr_repeat = RepeatAugDataset(tr_subset, repeats=N_REPEAT)\n",
    "\n",
    "    # --- DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        tr_repeat,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        va_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # --- ëª¨ë¸/ì˜µí‹°ë§ˆ/ìŠ¤ì¼€ì¤„ëŸ¬: í´ë“œë§ˆë‹¤ ìƒˆë¡œ ì´ˆê¸°í™”\n",
    "    model = safe_create_model(model_name, NUM_CLASSES, device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    total_steps = EPOCHS * len(train_loader)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    patience, bad = 4, 0\n",
    "    ckpt_path = f\"../results/checkpoints/{version}/{model_name}_{version}_fold{fold}.pth\"\n",
    "    os.makedirs(f\"../results/checkpoints{version}\", exist_ok=True)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n[Fold {fold}] Epoch {epoch+1}/{EPOCHS}\")\n",
    "        start = time.time()\n",
    "\n",
    "        tr = train_one_epoch(train_loader, model, optimizer, loss_fn, device, scheduler)\n",
    "        va = validate_one_epoch(val_loader,   model, loss_fn, device)\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"Train F1: {tr['train_f1']:.4f} | Val F1: {va['val_f1']:.4f} | \"\n",
    "              f\"Train Loss: {tr['train_loss']:.4f} | Val Loss: {va['val_loss']:.4f} | \"\n",
    "              f\"Elapsed: {elapsed:.2f}s\")\n",
    "\n",
    "        if va['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = va['val_f1']\n",
    "            torch.save({\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"val_f1\": best_val_f1,\n",
    "                \"fold\": fold,\n",
    "            }, ckpt_path)\n",
    "            print(\"âœ… Best (this fold) saved!\")\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(\"â¹ Early stopping (this fold).\")\n",
    "                break\n",
    "\n",
    "    best_ckpts.append(ckpt_path)\n",
    "\n",
    "print(\"\\nFold best checkpoints:\", best_ckpts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47729d2d",
   "metadata": {},
   "source": [
    "### inference & save submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v3_fold0.pth: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:23<00:00,  8.42it/s]\n",
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v3_fold1.pth: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:23<00:00,  8.35it/s]\n",
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v3_fold2.pth: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:23<00:00,  8.31it/s]\n",
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v3_fold3.pth: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:23<00:00,  8.36it/s]\n",
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v3_fold4.pth: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:23<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Saved submission: ../results/submission_tf_efficientnet_b6.aa_in1k_v3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== inference & save submission file (K-Fold probability averaging, no TTA) ==========\n",
    "\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ckpt_path in best_ckpts:\n",
    "        # í´ë“œë³„ ë² ìŠ¤íŠ¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
    "        state = torch.load(ckpt_path, map_location=device)\n",
    "        model = safe_create_model(model_name, NUM_CLASSES, device)\n",
    "        model.load_state_dict(state[\"state_dict\"])\n",
    "        model.eval()\n",
    "\n",
    "        fold_probs = []\n",
    "        for imgs, _ in tqdm(test_dataloader, desc=f\"Infer(Test) - {os.path.basename(ckpt_path)}\"):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            with autocast(enabled=(device.type == 'cuda')):\n",
    "                logits = model(imgs)                  # (N, C) on cuda (halfì¼ ìˆ˜ ìˆìŒ)\n",
    "                probs  = logits.float().softmax(1)   # â˜… GPUì—ì„œ FP32 softmax\n",
    "            fold_probs.append(probs.cpu())           # (N, C) on cpu float32\n",
    "\n",
    "        # (T, C) ì´ í´ë“œì˜ ì „ì²´ í™•ë¥ \n",
    "        all_probs.append(torch.cat(fold_probs, dim=0))\n",
    "\n",
    "# (F, T, C) â†’ í™•ë¥  í‰ê·  â†’ (T,)\n",
    "probs_mean = torch.stack(all_probs, dim=0).mean(0)   # cpu float32\n",
    "preds = probs_mean.argmax(1).numpy()\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ì €ì¥\n",
    "sub = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "sub[\"target\"] = preds[: len(sub)]\n",
    "out_path = f\"../results/submission_{model_name}_{version}.csv\"\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(f\"ğŸ“„ Saved submission: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
