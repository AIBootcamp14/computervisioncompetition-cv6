{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f534d9",
   "metadata": {},
   "source": [
    "### import & seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50b6594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import & seed 고정\n",
    "import os, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# 시드 고정\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True  # 속도 우선\n",
    "# torch.use_deterministic_algorithms(False)  # 재현성 우선이면 True로\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee03c60",
   "metadata": {},
   "source": [
    "### Settings (path/hyper parameters/device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818114c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings(path/hyper parameters/device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_path = '../data'\n",
    "model_name = 'tf_efficientnet_b6.aa_in1k'  # safe_create_model이 알아서 폴백 처리\n",
    "\n",
    "NUM_CLASSES = 17\n",
    "img_size = 528        # 224, 456, 528 등\n",
    "LR = 1e-3\n",
    "EPOCHS = 12\n",
    "BATCH_SIZE = 16\n",
    "num_workers = 32      # 환경에 따라 8~16 권장\n",
    "N_REPEAT = 4          # 같은 원본을 한 에폭에 3번 노출(서로 다른 증강 조합)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc8635",
   "metadata": {},
   "source": [
    "### dataset & repeat augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab6806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset & repeat augmentation\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"CSV: (filename, target) 형식 가정. 테스트에서는 target 칼럼이 dummy여도 OK.\"\"\"\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path).values  # [[name, target], ...]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.img_dir, name)))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "class RepeatAugDataset(Dataset):\n",
    "    \"\"\"같은 샘플을 repeats번 노출(호출마다 transform이 달라지므로 서로 다른 증강 조합으로 학습).\"\"\"\n",
    "    def __init__(self, base_dataset, repeats: int = 3):\n",
    "        self.base = base_dataset\n",
    "        self.repeats = repeats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base) * self.repeats\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_idx = idx // self.repeats\n",
    "        return self.base[base_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55afe56",
   "metadata": {},
   "source": [
    "### Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1afb37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1-lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1-lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a948649",
   "metadata": {},
   "source": [
    "### transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c329af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ===== Toggle here =====\n",
    "N_SOME = 4  # ← A/B 테스트 시 3 또는 4로만 바꾸면 됩니다.\n",
    "\n",
    "heavy_one = A.OneOf([  # 헤비급: 최대 1개만 선택\n",
    "    A.Perspective(scale=(0.05, 0.12), keep_size=True,\n",
    "                  pad_mode=cv2.BORDER_CONSTANT, pad_val=255),\n",
    "    A.Affine(translate_percent=(0.0, 0.08), scale=(0.95, 1.05),\n",
    "             shear=(-12, 12), cval=255, mode=cv2.BORDER_CONSTANT),\n",
    "    A.CoarseDropout(min_holes=1, max_holes=4,\n",
    "                    min_height=int(img_size*0.08), max_height=int(img_size*0.30),\n",
    "                    min_width=int(img_size*0.15),  max_width=int(img_size*0.40),\n",
    "                    fill_value=0),\n",
    "    A.CoarseDropout(min_holes=1, max_holes=4,\n",
    "                    min_height=int(img_size*0.08), max_height=int(img_size*0.30),\n",
    "                    min_width=int(img_size*0.15),  max_width=int(img_size*0.40),\n",
    "                    fill_value=255),\n",
    "    A.MotionBlur(blur_limit=(7, 11), allow_shifted=True),\n",
    "], p=1.0)\n",
    "\n",
    "light_pool = [\n",
    "    # 기존 변형들(선택되면 항상 적용되도록 p=1.0; 적용 개수는 SomeOf의 n으로 제어)\n",
    "    A.RandomRotate90(p=1.0),\n",
    "    A.Rotate(limit=180, border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    A.RandomBrightnessContrast(0.12, 0.12, p=1.0),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=int(img_size*1.15), interpolation=cv2.INTER_CUBIC),\n",
    "        A.PadIfNeeded(int(img_size*1.15), int(img_size*1.15),\n",
    "                      border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),\n",
    "        A.RandomResizedCrop(height=img_size, width=img_size,\n",
    "                            scale=(0.85, 1.0), ratio=(0.9, 1.1), p=1.0),\n",
    "    ]),\n",
    "    A.Downscale(scale_min=0.85, scale_max=0.96, p=1.0),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "    A.ImageCompression(quality_lower=40, quality_upper=85, p=1.0),\n",
    "    A.GaussNoise(var_limit=(5.0, 20.0), p=1.0),\n",
    "\n",
    "    # 컬러/톤/채널 변형(실물 데이터의 색 캐스트 대응)\n",
    "    A.HueSaturationValue(hue_shift_limit=12, sat_shift_limit=25, val_shift_limit=15, p=1.0),\n",
    "    A.RandomGamma(gamma_limit=(60, 140), p=1.0),\n",
    "    A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=1.0),\n",
    "    A.CLAHE(clip_limit=(1, 3), tile_grid_size=(8, 8), p=1.0),\n",
    "    A.ToGray(p=1.0),\n",
    "    A.InvertImg(p=1.0),\n",
    "]\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.SomeOf(\n",
    "        [heavy_one] + light_pool,  # 헤비 1개까지 + 라이트 풀에서 선택\n",
    "        n=N_SOME,\n",
    "        p=1.0\n",
    "    ),\n",
    "    A.Resize(img_size, img_size, interpolation=cv2.INTER_CUBIC),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_CUBIC),\n",
    "    A.PadIfNeeded(img_size, img_size, border_mode=cv2.BORDER_CONSTANT, value=255),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd373b0",
   "metadata": {},
   "source": [
    "### data load & train/val split -> dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78f31043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1570, 197)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [셀 5-K] K-Fold 분할 & DataLoader 준비 (무TTA)\n",
    "FOLDS = 5\n",
    "\n",
    "# 전체 train 로드 (변경 없음)\n",
    "train_dataset_full = ImageDataset(\n",
    "    os.path.join(data_path, \"train.csv\"),\n",
    "    os.path.join(data_path, \"train\"),\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "# 테스트 로더는 폴드와 무관하므로 여기서 한 번만 만들어 둡니다.\n",
    "test_dataset = ImageDataset(\n",
    "    os.path.join(data_path, \"sample_submission.csv\"),\n",
    "    os.path.join(data_path, \"test\"),\n",
    "    transform=test_transforms\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# 폴드 분할에서 사용될 라벨\n",
    "y_all = train_dataset_full.df[:, 1].astype(int)\n",
    "\n",
    "# StratifiedKFold 객체 (셔플 권장)\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# 이후 셀 8에서 폴드 루프를 돌릴 것이므로 여기서는 로더를 만들지 않습니다.\n",
    "# 각 fold마다 train/val Subset과 DataLoader는 셀 8에서 생성합니다.\n",
    "len(train_dataset_full), len(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ec9c4",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c9abe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def safe_create_model(model_name: str, num_classes: int, device):\n",
    "    tried = []\n",
    "    def _try(name, **kw):\n",
    "        tried.append(name)\n",
    "        return timm.create_model(name, pretrained=True, num_classes=num_classes, **kw).to(device)\n",
    "\n",
    "    try:\n",
    "        return _try(model_name, drop_rate=0.3, drop_path_rate=0.1)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return _try(model_name, drop_rate=0.3)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "\n",
    "    fallbacks = [\n",
    "        model_name.replace('.', '_'),\n",
    "        'tf_efficientnet_b6_ns',\n",
    "        'tf_efficientnet_b6',\n",
    "        'tf_efficientnet_b4_ns',\n",
    "        'convnext_tiny',\n",
    "    ]\n",
    "    for fb in fallbacks:\n",
    "        try:\n",
    "            return _try(fb, drop_rate=0.3)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    raise RuntimeError(f\"create_model 실패. 시도: {tried} | last_err: {last_err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35373d",
   "metadata": {},
   "source": [
    "### train/valid roof definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "960b3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/valid roof definition\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scheduler=None, mixup_alpha=0.4):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=(device.type == \"cuda\")):\n",
    "            if mixup_alpha > 0:\n",
    "                inputs, targets_a, targets_b, lam = mixup_data(images, targets, mixup_alpha)\n",
    "                logits = model(inputs)\n",
    "                loss = mixup_criterion(loss_fn, logits, targets_a, targets_b, lam)\n",
    "            else:\n",
    "                logits = model(images)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # ✅ 배치 단위로 LR 스케줄 진행\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # --- 메트릭 누적 ---\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(logits.argmax(1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        # 진행바에 현재 LR 표시(선택)\n",
    "        if scheduler is not None:\n",
    "            # optimizer에 그룹이 여러 개면 첫 그룹 기준\n",
    "            curr_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            pbar.set_description(f\"Loss: {loss.item():.4f} | LR: {curr_lr:.2e}\")\n",
    "        else:\n",
    "            pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # 평균(배치 평균). 샘플 가중 평균을 원하면 batch_size로 가중하세요.\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1  = f1_score(targets_list, preds_list, average=\"macro\")\n",
    "\n",
    "    return {\"train_loss\": train_loss, \"train_acc\": train_acc, \"train_f1\": train_f1}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    for images, targets in tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with autocast():\n",
    "            logits = model(images)\n",
    "            loss = loss_fn(logits, targets)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        preds_list.extend(logits.argmax(1).cpu().numpy())\n",
    "        targets_list.extend(targets.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1  = f1_score(targets_list, preds_list, average='macro')\n",
    "    return {\"val_loss\": val_loss, \"val_acc\": val_acc, \"val_f1\": val_f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e597d",
   "metadata": {},
   "source": [
    "### model/loss/optim/scheduler & train loof + checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "345a6040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 0 / 4 ==========\n",
      "\n",
      "[Fold 0] Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6214 | LR: 9.83e-04: 100%|██████████| 314/314 [01:34<00:00,  3.33it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.4040 | Val F1: 0.8759 | Train Loss: 1.2711 | Val Loss: 0.3121 | Elapsed: 98.12s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5318 | LR: 9.33e-04: 100%|██████████| 314/314 [01:39<00:00,  3.16it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.4957 | Val F1: 0.9056 | Train Loss: 1.0043 | Val Loss: 0.3019 | Elapsed: 103.37s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0546 | LR: 8.54e-04: 100%|██████████| 314/314 [01:40<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.4878 | Val F1: 0.9197 | Train Loss: 0.8791 | Val Loss: 0.2324 | Elapsed: 105.25s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1992 | LR: 7.50e-04: 100%|██████████| 314/314 [01:40<00:00,  3.12it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5529 | Val F1: 0.9250 | Train Loss: 0.7930 | Val Loss: 0.2701 | Elapsed: 104.48s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0981 | LR: 6.30e-04: 100%|██████████| 314/314 [01:40<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5448 | Val F1: 0.9413 | Train Loss: 0.7731 | Val Loss: 0.2121 | Elapsed: 104.66s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5910 | LR: 5.00e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5573 | Val F1: 0.9486 | Train Loss: 0.7395 | Val Loss: 0.2264 | Elapsed: 105.16s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4853 | LR: 3.71e-04: 100%|██████████| 314/314 [01:40<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5339 | Val F1: 0.9668 | Train Loss: 0.6604 | Val Loss: 0.2146 | Elapsed: 104.84s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 0] Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8053 | LR: 2.51e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5383 | Val F1: 0.9666 | Train Loss: 0.6124 | Val Loss: 0.1613 | Elapsed: 104.98s\n",
      "\n",
      "[Fold 0] Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1721 | LR: 1.47e-04: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5840 | Val F1: 0.9380 | Train Loss: 0.5679 | Val Loss: 0.1918 | Elapsed: 105.49s\n",
      "\n",
      "[Fold 0] Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2959 | LR: 6.79e-05: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5051 | Val F1: 0.9565 | Train Loss: 0.5637 | Val Loss: 0.1666 | Elapsed: 105.68s\n",
      "\n",
      "[Fold 0] Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9193 | LR: 1.80e-05: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5838 | Val F1: 0.9592 | Train Loss: 0.5438 | Val Loss: 0.1659 | Elapsed: 105.31s\n",
      "⏹ Early stopping (this fold).\n",
      "\n",
      "========== Fold 1 / 4 ==========\n",
      "\n",
      "[Fold 1] Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5501 | LR: 9.83e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.4229 | Val F1: 0.8735 | Train Loss: 1.3241 | Val Loss: 0.4302 | Elapsed: 105.19s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5206 | LR: 9.33e-04: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5062 | Val F1: 0.8698 | Train Loss: 1.0131 | Val Loss: 0.4393 | Elapsed: 105.40s\n",
      "\n",
      "[Fold 1] Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9369 | LR: 8.54e-04: 100%|██████████| 314/314 [01:40<00:00,  3.12it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5593 | Val F1: 0.9243 | Train Loss: 0.8992 | Val Loss: 0.2776 | Elapsed: 104.87s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6581 | LR: 7.50e-04: 100%|██████████| 314/314 [01:40<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5108 | Val F1: 0.9308 | Train Loss: 0.8135 | Val Loss: 0.2209 | Elapsed: 104.79s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1256 | LR: 6.30e-04: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5403 | Val F1: 0.9438 | Train Loss: 0.7676 | Val Loss: 0.2419 | Elapsed: 105.55s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9214 | LR: 5.00e-04: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5255 | Val F1: 0.9362 | Train Loss: 0.7354 | Val Loss: 0.2329 | Elapsed: 105.56s\n",
      "\n",
      "[Fold 1] Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3442 | LR: 3.71e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5666 | Val F1: 0.9590 | Train Loss: 0.6641 | Val Loss: 0.1930 | Elapsed: 105.20s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9346 | LR: 2.51e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5459 | Val F1: 0.9383 | Train Loss: 0.6463 | Val Loss: 0.2122 | Elapsed: 105.16s\n",
      "\n",
      "[Fold 1] Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4312 | LR: 1.47e-04: 100%|██████████| 314/314 [01:40<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5560 | Val F1: 0.9648 | Train Loss: 0.5505 | Val Loss: 0.1399 | Elapsed: 104.81s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 1] Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6589 | LR: 6.79e-05: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5349 | Val F1: 0.9503 | Train Loss: 0.5722 | Val Loss: 0.1707 | Elapsed: 105.56s\n",
      "\n",
      "[Fold 1] Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0947 | LR: 1.80e-05: 100%|██████████| 314/314 [01:41<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5758 | Val F1: 0.9522 | Train Loss: 0.5599 | Val Loss: 0.1521 | Elapsed: 104.88s\n",
      "\n",
      "[Fold 1] Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4928 | LR: 1.00e-06: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5311 | Val F1: 0.9465 | Train Loss: 0.5501 | Val Loss: 0.1492 | Elapsed: 105.62s\n",
      "\n",
      "========== Fold 2 / 4 ==========\n",
      "\n",
      "[Fold 2] Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5955 | LR: 9.83e-04: 100%|██████████| 314/314 [01:42<00:00,  3.07it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.3994 | Val F1: 0.8852 | Train Loss: 1.3003 | Val Loss: 0.3178 | Elapsed: 106.31s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3920 | LR: 9.33e-04: 100%|██████████| 314/314 [01:42<00:00,  3.08it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5308 | Val F1: 0.9185 | Train Loss: 1.0021 | Val Loss: 0.3008 | Elapsed: 106.07s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4921 | LR: 8.54e-04: 100%|██████████| 314/314 [01:42<00:00,  3.06it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5348 | Val F1: 0.9084 | Train Loss: 0.9166 | Val Loss: 0.2516 | Elapsed: 106.71s\n",
      "\n",
      "[Fold 2] Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3231 | LR: 7.50e-04: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5500 | Val F1: 0.9437 | Train Loss: 0.7993 | Val Loss: 0.1891 | Elapsed: 105.63s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2070 | LR: 6.30e-04: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5613 | Val F1: 0.9301 | Train Loss: 0.7524 | Val Loss: 0.2055 | Elapsed: 105.46s\n",
      "\n",
      "[Fold 2] Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1713 | LR: 5.00e-04: 100%|██████████| 314/314 [01:42<00:00,  3.08it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5466 | Val F1: 0.9361 | Train Loss: 0.7228 | Val Loss: 0.1734 | Elapsed: 105.90s\n",
      "\n",
      "[Fold 2] Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0292 | LR: 3.71e-04: 100%|██████████| 314/314 [01:41<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5223 | Val F1: 0.9620 | Train Loss: 0.6839 | Val Loss: 0.1349 | Elapsed: 105.00s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0216 | LR: 2.51e-04: 100%|██████████| 314/314 [01:40<00:00,  3.12it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5712 | Val F1: 0.9651 | Train Loss: 0.6036 | Val Loss: 0.1463 | Elapsed: 104.83s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7745 | LR: 1.47e-04: 100%|██████████| 314/314 [01:40<00:00,  3.12it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5273 | Val F1: 0.9607 | Train Loss: 0.6114 | Val Loss: 0.1119 | Elapsed: 104.55s\n",
      "\n",
      "[Fold 2] Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1886 | LR: 6.79e-05: 100%|██████████| 314/314 [01:40<00:00,  3.12it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5593 | Val F1: 0.9762 | Train Loss: 0.5915 | Val Loss: 0.1159 | Elapsed: 104.70s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 2] Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2395 | LR: 1.80e-05: 100%|██████████| 314/314 [01:40<00:00,  3.13it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5688 | Val F1: 0.9646 | Train Loss: 0.5492 | Val Loss: 0.1252 | Elapsed: 104.41s\n",
      "\n",
      "[Fold 2] Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7462 | LR: 1.00e-06: 100%|██████████| 314/314 [01:40<00:00,  3.14it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5393 | Val F1: 0.9689 | Train Loss: 0.5179 | Val Loss: 0.1297 | Elapsed: 104.04s\n",
      "\n",
      "========== Fold 3 / 4 ==========\n",
      "\n",
      "[Fold 3] Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4732 | LR: 9.83e-04: 100%|██████████| 314/314 [01:40<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.4509 | Val F1: 0.8790 | Train Loss: 1.3044 | Val Loss: 0.3895 | Elapsed: 104.73s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0404 | LR: 9.33e-04: 100%|██████████| 314/314 [01:40<00:00,  3.14it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.4751 | Val F1: 0.8565 | Train Loss: 1.0126 | Val Loss: 0.4088 | Elapsed: 103.97s\n",
      "\n",
      "[Fold 3] Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1563 | LR: 8.54e-04: 100%|██████████| 314/314 [01:40<00:00,  3.13it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5413 | Val F1: 0.9090 | Train Loss: 0.9281 | Val Loss: 0.2473 | Elapsed: 104.10s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3088 | LR: 7.50e-04: 100%|██████████| 314/314 [01:40<00:00,  3.12it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5363 | Val F1: 0.9332 | Train Loss: 0.7906 | Val Loss: 0.2353 | Elapsed: 104.45s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8856 | LR: 6.30e-04: 100%|██████████| 314/314 [01:40<00:00,  3.12it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5372 | Val F1: 0.9359 | Train Loss: 0.7200 | Val Loss: 0.2427 | Elapsed: 104.47s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4760 | LR: 5.00e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5383 | Val F1: 0.9413 | Train Loss: 0.7172 | Val Loss: 0.1774 | Elapsed: 105.15s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6318 | LR: 3.71e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5287 | Val F1: 0.9471 | Train Loss: 0.6512 | Val Loss: 0.2090 | Elapsed: 105.25s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8445 | LR: 2.51e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5401 | Val F1: 0.9695 | Train Loss: 0.6351 | Val Loss: 0.1634 | Elapsed: 105.35s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 3] Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2271 | LR: 1.47e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5434 | Val F1: 0.9561 | Train Loss: 0.6170 | Val Loss: 0.1910 | Elapsed: 105.24s\n",
      "\n",
      "[Fold 3] Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4070 | LR: 6.79e-05: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5501 | Val F1: 0.9563 | Train Loss: 0.5600 | Val Loss: 0.1619 | Elapsed: 105.40s\n",
      "\n",
      "[Fold 3] Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8894 | LR: 1.80e-05: 100%|██████████| 314/314 [01:40<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5623 | Val F1: 0.9538 | Train Loss: 0.5719 | Val Loss: 0.1780 | Elapsed: 104.91s\n",
      "\n",
      "[Fold 3] Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8731 | LR: 1.00e-06: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5295 | Val F1: 0.9569 | Train Loss: 0.5421 | Val Loss: 0.1694 | Elapsed: 105.20s\n",
      "⏹ Early stopping (this fold).\n",
      "\n",
      "========== Fold 4 / 4 ==========\n",
      "\n",
      "[Fold 4] Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3984 | LR: 9.83e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.4517 | Val F1: 0.8587 | Train Loss: 1.2935 | Val Loss: 0.3480 | Elapsed: 105.33s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5944 | LR: 9.33e-04: 100%|██████████| 314/314 [01:42<00:00,  3.07it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.4978 | Val F1: 0.8616 | Train Loss: 0.9860 | Val Loss: 0.3905 | Elapsed: 105.96s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7888 | LR: 8.54e-04: 100%|██████████| 314/314 [01:41<00:00,  3.08it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5262 | Val F1: 0.9100 | Train Loss: 0.8793 | Val Loss: 0.3130 | Elapsed: 106.01s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5360 | LR: 7.50e-04: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5308 | Val F1: 0.9424 | Train Loss: 0.8065 | Val Loss: 0.2268 | Elapsed: 105.33s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5873 | LR: 6.30e-04: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5330 | Val F1: 0.9150 | Train Loss: 0.7385 | Val Loss: 0.2572 | Elapsed: 105.68s\n",
      "\n",
      "[Fold 4] Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5975 | LR: 5.00e-04: 100%|██████████| 314/314 [01:42<00:00,  3.06it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5411 | Val F1: 0.9535 | Train Loss: 0.6948 | Val Loss: 0.1707 | Elapsed: 106.60s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5487 | LR: 3.71e-04: 100%|██████████| 314/314 [01:41<00:00,  3.08it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5394 | Val F1: 0.9437 | Train Loss: 0.7224 | Val Loss: 0.1889 | Elapsed: 106.14s\n",
      "\n",
      "[Fold 4] Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7755 | LR: 2.51e-04: 100%|██████████| 314/314 [01:42<00:00,  3.06it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5843 | Val F1: 0.9625 | Train Loss: 0.6055 | Val Loss: 0.2026 | Elapsed: 106.82s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9201 | LR: 1.47e-04: 100%|██████████| 314/314 [01:42<00:00,  3.06it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5579 | Val F1: 0.9530 | Train Loss: 0.5885 | Val Loss: 0.1760 | Elapsed: 106.51s\n",
      "\n",
      "[Fold 4] Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6314 | LR: 6.79e-05: 100%|██████████| 314/314 [01:42<00:00,  3.07it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5470 | Val F1: 0.9590 | Train Loss: 0.5605 | Val Loss: 0.1499 | Elapsed: 106.33s\n",
      "\n",
      "[Fold 4] Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2279 | LR: 1.80e-05: 100%|██████████| 314/314 [01:41<00:00,  3.09it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5508 | Val F1: 0.9672 | Train Loss: 0.5515 | Val Loss: 0.1636 | Elapsed: 105.69s\n",
      "✅ Best (this fold) saved!\n",
      "\n",
      "[Fold 4] Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3313 | LR: 1.00e-06: 100%|██████████| 314/314 [01:41<00:00,  3.10it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.5395 | Val F1: 0.9543 | Train Loss: 0.5381 | Val Loss: 0.1839 | Elapsed: 105.07s\n",
      "\n",
      "Fold best checkpoints: ['../results/checkpoints/tf_efficientnet_b6.aa_in1k_v1/tf_efficientnet_b6.aa_in1k_v1_fold0.pth', '../results/checkpoints/tf_efficientnet_b6.aa_in1k_v1/tf_efficientnet_b6.aa_in1k_v1_fold1.pth', '../results/checkpoints/tf_efficientnet_b6.aa_in1k_v1/tf_efficientnet_b6.aa_in1k_v1_fold2.pth', '../results/checkpoints/tf_efficientnet_b6.aa_in1k_v1/tf_efficientnet_b6.aa_in1k_v1_fold3.pth', '../results/checkpoints/tf_efficientnet_b6.aa_in1k_v1/tf_efficientnet_b6.aa_in1k_v1_fold4.pth']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model/loss/optim/scheduler & train loof + checkpoint\n",
    "model = safe_create_model(model_name, NUM_CLASSES, device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "version = 'v1'\n",
    "best_val_f1 = 0.0\n",
    "patience, bad = 4, 0\n",
    "\n",
    "best_ckpts = []  # 폴드별 최고 성능 모델 경로 저장\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(np.arange(len(train_dataset_full)), y_all)):\n",
    "    print(f\"\\n========== Fold {fold} / {FOLDS-1} ==========\")\n",
    "\n",
    "    # --- 폴드별 Subset\n",
    "    tr_subset = Subset(train_dataset_full, tr_idx)\n",
    "    va_subset = Subset(train_dataset_full, va_idx)\n",
    "\n",
    "    # --- 학습만 반복 노출 (같은 원본을 서로 다른 증강 조합으로 N회 보이기)\n",
    "    tr_repeat = RepeatAugDataset(tr_subset, repeats=N_REPEAT)\n",
    "\n",
    "    # --- DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        tr_repeat,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        va_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # --- 모델/옵티마/스케줄러: 폴드마다 새로 초기화\n",
    "    model = safe_create_model(model_name, NUM_CLASSES, device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    total_steps = EPOCHS * len(train_loader)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    patience, bad = 4, 0\n",
    "    ckpt_path = f\"../results/checkpoints/{model_name}_{version}/{model_name}_{version}_fold{fold}.pth\"\n",
    "    os.makedirs(f\"../results/checkpoints/{model_name}_{version}\", exist_ok=True)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n[Fold {fold}] Epoch {epoch+1}/{EPOCHS}\")\n",
    "        start = time.time()\n",
    "\n",
    "        tr = train_one_epoch(train_loader, model, optimizer, loss_fn, device, scheduler, mixup_alpha=0.5)\n",
    "        va = validate_one_epoch(val_loader,   model, loss_fn, device)\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"Train F1: {tr['train_f1']:.4f} | Val F1: {va['val_f1']:.4f} | \"\n",
    "              f\"Train Loss: {tr['train_loss']:.4f} | Val Loss: {va['val_loss']:.4f} | \"\n",
    "              f\"Elapsed: {elapsed:.2f}s\")\n",
    "\n",
    "        if va['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = va['val_f1']\n",
    "            torch.save({\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"val_f1\": best_val_f1,\n",
    "                \"fold\": fold,\n",
    "            }, ckpt_path)\n",
    "            print(\"✅ Best (this fold) saved!\")\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(\"⏹ Early stopping (this fold).\")\n",
    "                break\n",
    "\n",
    "    best_ckpts.append(ckpt_path)\n",
    "\n",
    "print(\"\\nFold best checkpoints:\", best_ckpts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47729d2d",
   "metadata": {},
   "source": [
    "### inference & save submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1d3d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v1_fold0.pth: 100%|██████████| 197/197 [00:19<00:00, 10.22it/s]\n",
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v1_fold1.pth: 100%|██████████| 197/197 [00:19<00:00, 10.31it/s]\n",
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v1_fold2.pth: 100%|██████████| 197/197 [00:19<00:00, 10.15it/s]\n",
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v1_fold3.pth: 100%|██████████| 197/197 [00:19<00:00, 10.26it/s]\n",
      "Infer(Test) - tf_efficientnet_b6.aa_in1k_v1_fold4.pth: 100%|██████████| 197/197 [00:19<00:00, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Saved submission: ../results/submission_tf_efficientnet_b6.aa_in1k_v1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== inference & save submission file (K-Fold probability averaging, no TTA) ==========\n",
    "\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ckpt_path in best_ckpts:\n",
    "        # 폴드별 베스트 체크포인트 로드\n",
    "        state = torch.load(ckpt_path, map_location=device)\n",
    "        model = safe_create_model(model_name, NUM_CLASSES, device)\n",
    "        model.load_state_dict(state[\"state_dict\"])\n",
    "        model.eval()\n",
    "\n",
    "        fold_probs = []\n",
    "        for imgs, _ in tqdm(test_dataloader, desc=f\"Infer(Test) - {os.path.basename(ckpt_path)}\"):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            with autocast(enabled=(device.type == 'cuda')):\n",
    "                logits = model(imgs)                  # (N, C) on cuda (half일 수 있음)\n",
    "                probs  = logits.float().softmax(1)   # ★ GPU에서 FP32 softmax\n",
    "            fold_probs.append(probs.cpu())           # (N, C) on cpu float32\n",
    "\n",
    "        # (T, C) 이 폴드의 전체 확률\n",
    "        all_probs.append(torch.cat(fold_probs, dim=0))\n",
    "\n",
    "# (F, T, C) → 확률 평균 → (T,)\n",
    "probs_mean = torch.stack(all_probs, dim=0).mean(0)   # cpu float32\n",
    "preds = probs_mean.argmax(1).numpy()\n",
    "\n",
    "# 제출 파일 저장\n",
    "sub = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "sub[\"target\"] = preds[: len(sub)]\n",
    "out_path = f\"../results/submission_{model_name}_{version}.csv\"\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(f\"📄 Saved submission: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
